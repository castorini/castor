This dataset is taken from: https://research.fb.com/downloads/babi/
This directory excludes the directory called 'freebase-subsets' since it 
is too large to be included in GitHub. If needed please download it from
that link.

I have provided an extra directory called 'scripts' that contains 
Python scripts to dump pickles for word vector mapping, word to index maps
and label to index maps. It is required to provide the path to the 
300-dim Google pre-trained word embeddings in the file 'extract_relevant_words_SQ'.


Check the file - FB-README.txt - for the main description of the dataset.